---
title: "AI for better or worse: a reflection"
date: "2024-11-30T13:50:08.529Z"
description: "After reading Dario Amodei’s letter “Machine of Loving grace\", I wanted to share my thoughts on this complex topic."
available: true
image: ""
link: "https://hugodemenez.substack.com/p/ai-for-better-or-worse-a-reflection"
---

# AI for better or worse: a reflection

<Date date="2024-11-30T13:50:08.529Z" />


After reading [Dario Amodei’s letter](https://darioamodei.com/machines-of-loving-grace)*[“Machine of Loving grace"](https://darioamodei.com/machines-of-loving-grace)*, I wanted to share my thoughts on this complex topic.

Dario is deeply immersed in AI. As the CEO and co-founder of Anthropic, a leading AI research company, he brings years of expertise in the field, having previously worked at OpenAI.

He knows much more than I do. But as a developer and startup founder, I feel I have a strong perspective as a daily user of AI tools.

**Sparks**

AI sparks ideas.

It helps me draft, refine, and explore new angles.

I’ve never been so “productive” and “unproductive” at the same time.

AI lets me generate more ideas and iterate endlessly. I’m not exaggerating when I say I can draft and redraft 100 times more than before.

But AI isn’t fast enough yet.

For example, if you’ve used dev tools like Bolt (for non-developers), Cursor, or Copilot, you know what I mean.

I sometimes leave my desk while AI does its job as it takes so long, and worse… when I return, there’s often an error. This leads to more prompts or solving issues myself.

This was a problem in the past, and though it has improved, the issue persists.

**The risks**

AI in dev tools can cause harm.

I haven’t seen any dev tools actively check for cyber risks during development.

the lack of built-in cybersecurity checks in AI development tools presents a significant gap.

For developers / entrepreneurs like me, this gap opens up opportunities to create tools that proactively address these risks.

On the other side, many junior developers start out using these tools. But they don’t understand cyber risks.

Marc Louvion’s recent drama highlights this.

His SaaS platform grew quickly, but he ignored cyber risks. When cyber-savvy users tested his sites, problems emerged.

This is why I talk a lot about App-Prove. Our goal is to make cybersecurity audits easier. Developers should feel empowered to build securely.

**Democracy and bias**

In his letter, Dario talks about AI being good for democracy if it is developed by democracies.

This made me think about democracies today.

Take France. It’s a democracy in theory, but it doesn’t always feel like one.

People here are allowed to share opinions, but many voices are silenced. “Non-aligned” views face backlash.

During the last elections, I noticed this with the far-right. Though they had over 20% of the vote, they were repressed by everyone else—left, right, and center.

It made me wonder: is this how a democracy should work?

Dario says AI must be “non-biased” to serve democracy. But I don’t believe AI can ever be truly unbiased.

Why?

Bias is part of reasoning. If you remove all bias, AI can’t find solutions or make decisions. Every answer would need endless questioning.

And in politics, there’s no “physical proof” of truth.

**A reminder**

AI developers don’t have all the answers.

They aren’t as all-knowing as we might think. They miss things.

This is why we need to speak up. Share opinions. Push back.

If we stay silent, we risk creating AI that works against us.

We need to guide AI to be good—not just hope it turns out that way.
